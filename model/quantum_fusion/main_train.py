# -*- coding: utf-8 -*-
"""quantum_fusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sufKkTUOqgRni0IY8aHQhI2a9Y-OCoXz
"""

# !pip install qiskit qiskit-aer qiskit-machine-learning

# !pip install ingenii_quantum

# !pip install pennylane-qiskit

# !pip uninstall -y qiskit qiskit-aer qiskit-ibm-runtime sympy ingenii-quantum pennylane-qiskit torch torchvision torchaudio

# !pip install qiskit qiskit-aer qiskit-ibm-runtime sympy ingenii-quantum pennylane-qiskit torch torchvision torchaudio

from tqdm import tqdm

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr, spearmanr
import math
import pennylane as qml
# Make sure you have installed the Ingenii quantum package:
# !pip install ingenii-quantum
from ingenii_quantum.hybrid_networks.layers import QuantumFCLayer

# ---------------- Notebook Configuration ----------------
# Set paths and hyperparameters directly in the notebook
sgcnn_results_dir = "/content"
cnn3d_results_dir = "/content"
output_dir         = "/content/results"

# ---------------- Data Alignment Functions ----------------
class FusionDataset(Dataset):
    def __init__(self, sgcnn_features, cnn3d_features, labels):
        self.sgcnn_features = torch.FloatTensor(sgcnn_features)
        self.cnn3d_features = torch.FloatTensor(cnn3d_features)
        self.labels = torch.FloatTensor(labels).unsqueeze(1)
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        return self.sgcnn_features[idx], self.cnn3d_features[idx], self.labels[idx]


def align_features(sgcnn_feat_path, sgcnn_ids_path, cnn3d_feat_path, cnn3d_ids_path):
    sgcnn_features = np.load(sgcnn_feat_path)
    sgcnn_ids = np.load(sgcnn_ids_path)
    cnn3d_features = np.load(cnn3d_feat_path)
    cnn3d_ids = np.load(cnn3d_ids_path)
    sg_map = {str(v):i for i,v in enumerate(sgcnn_ids)}
    c3_map = {str(v):i for i,v in enumerate(cnn3d_ids)}
    common = set(sg_map) & set(c3_map)
    sg_list, c3_list, ids = [], [], []
    for cid in common:
        sg_list.append(sgcnn_features[sg_map[cid]])
        c3_list.append(cnn3d_features[c3_map[cid]])
        ids.append(cid)
    return np.array(sg_list), np.array(c3_list), ids


def load_labels_from_csv(csv_path, complex_ids):
    df = pd.read_csv(csv_path)
    label_map = {str(r['complex_id']): float(r['label']) for _,r in df.iterrows()}
    return np.array([label_map[cid] for cid in complex_ids])


def evaluate_model(model, loader):
    model.eval()
    preds, labs = [], []
    with torch.no_grad():
        for sg, c3, y in loader:
            combined = torch.cat([sg, c3], dim=1)
            out = model(combined)
            preds.extend(out.cpu().numpy().flatten())
            labs.extend(y.cpu().numpy().flatten())
    preds, labs = np.array(preds), np.array(labs)
    return (math.sqrt(mean_squared_error(labs, preds)),
            mean_absolute_error(labs, preds),
            r2_score(labs, preds),
            pearsonr(labs, preds)[0],
            spearmanr(labs, preds)[0])

# ---------------- Model Definition ----------------
import math
import torch
import torch.nn as nn
from ingenii_quantum.hybrid_networks.layers import QuantumFCLayer

class ModelHybridFC(nn.Module):
    def __init__(self,
                 in_features:   int,
                 out_features:  int,
                 qc_input_size: int = 4,         # number of qubits
                 qc_n_layers:   int = 10,        # depth L = 10
                 qc_encoding:   str = 'amplitude',
                 qc_ansatz:     int = 1,
                 backend:       str = 'default.qubit'
                ):
        super().__init__()
        # 1) Classical compressor → qc_input_size dims
        self.fc1 = nn.Linear(in_features, 2 * qc_input_size)
        self.fc2 = nn.Linear(2 * qc_input_size, qc_input_size)

        # 2) Quantum layer: measures Z on each of qc_input_size wires
        qnn = QuantumFCLayer(
            input_size=qc_input_size,
            n_layers=qc_n_layers,
            encoding=qc_encoding,
            ansatz=qc_ansatz,
            observables=["ZI", "IZ"],      # one Z per qubit by default
            backend=backend
        )
        self.quantum_layer = qnn.create_layer(type_layer='torch')

        # 3) Final head: we’ll sum the per‑qubit outputs to shape [batch,1]
        self.fc_out = nn.Linear(1, out_features)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # → Classical preprocessing
        x = torch.relu(self.fc1(x))
        x = torch.tanh(self.fc2(x)) * math.pi

        # → Quantum measurements: out shape [batch, qc_input_size]
        q_out = self.quantum_layer(x)

        # → Sum over qubits → [batch,1]
        q_sum = q_out.sum(dim=1, keepdim=True)

        # → Final regression/classification head
        return self.fc_out(q_sum)


# ------------ Hyperparameters ------------------------

epochs = 100
batch_size = 32
lr = 0.001
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ---------------- Load & Prepare Data ----------------
datasets = {}
for split in ['train','val','test']:
    sg_feat = os.path.join(sgcnn_results_dir, f"refined_{split}_feat.npy")
    sg_ids  = os.path.join(sgcnn_results_dir, f"refined_{split}_complex_ids.npy")
    c3_feat = os.path.join(cnn3d_results_dir, f"3dcnn_dropout_05_best_val_refined_3d_{split}_feat.npy")
    c3_ids  = os.path.join(cnn3d_results_dir, f"3dcnn_dropout_05_best_val_refined_3d_{split}_complex_ids.npy")
    csv     = os.path.join(sgcnn_results_dir, f"refined_{split}_pred.csv")
    sg, c3, ids = align_features(sg_feat, sg_ids, c3_feat, c3_ids)
    labels = load_labels_from_csv(csv, ids)
    datasets[split] = {'sg': sg, 'c3': c3, 'y': labels, 'ids': ids}
    print(f"Loaded {split}: {len(ids)} samples")

# DataLoaders
loaders = {}
dims = datasets['train']['sg'].shape[1] + datasets['train']['c3'].shape[1]
for split in ['train','val','test']:
    ds = FusionDataset(
        datasets[split]['sg'], datasets[split]['c3'],
        datasets[split]['y']
    )
    shuffle = (split=='train')
    loaders[split] = DataLoader(ds, batch_size=batch_size, shuffle=shuffle)

# ---------------- Instantiate & Train ----------------
# Number of qubits = ceil(log2(16)) = 4
qc_input_size = 4
# Use Circuit 1
qc_ansatz     = 1
# Use amplitude encoding
qc_encoding   = 'amplitude'
# Depth L = 10
qc_n_layers   = 10

model = ModelHybridFC(
    in_features=dims,
    out_features=1,
    qc_input_size=qc_input_size,
    qc_n_layers=qc_n_layers,
    qc_encoding=qc_encoding,
    qc_ansatz=qc_ansatz,
    backend='default.qubit',             # or another PennyLane device
)
model.to(device)

optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
criterion = nn.MSELoss()

# Training
best_val = float('inf')
for epoch in range(1, epochs+1):
    model.train()
    train_loss = 0.0
    for sg, c3, y in tqdm(loaders['train']):
        x = torch.cat([sg, c3], dim=1).to(device)
        y = y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        train_loss += loss.item()
    train_loss /= len(loaders['train'])

    rmse, mae, r2, pearson, spearman = evaluate_model(model, loaders['val'])
    scheduler.step(rmse)

    print(f"Epoch {epoch}: Train RMSE={math.sqrt(train_loss):.4f}, Val RMSE={rmse:.4f}")
    if rmse < best_val:
        best_val = rmse
        torch.save(model.state_dict(), os.path.join(output_dir, 'best_model.pth'))

# Final evaluation on test set
model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))
print("Test metrics:", evaluate_model(model, loaders['test']))
